{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle sentiment-analysis-on-movie-reviews\n",
    "https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/storage/rotten-tomatos-sentiment-analysis')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Config.data_path()/'rotten-tomatos-sentiment-analysis'\n",
    "path.mkdir(parents=True, exist_ok=True)\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
      "test.tsv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
      "sampleSubmission.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
      "train.tsv.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "! kaggle competitions download -c sentiment-analysis-on-movie-reviews -p {path} \n",
    "! unzip -q -n {path}/test.tsv.zip -d {path}\n",
    "! unzip -q -n {path}/train.tsv.zip -d {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampleSubmission.csv  test.tsv\ttest.tsv.zip  train.tsv  train.tsv.zip\r\n"
     ]
    }
   ],
   "source": [
    "! ls {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>of escapades demonstrating the adage that what...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>escapades demonstrating the adage that what is...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>escapades</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>demonstrating the adage that what is good for ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>demonstrating the adage</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>demonstrating</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>the adage</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>adage</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>that what is good for the goose</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>that</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>what is good for the goose</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>what</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>is good for the goose</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>is</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>good for the goose</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>good</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>for the goose</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>for</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>the goose</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>goose</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>is also good for the gander , some of which oc...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>is also good for the gander , some of which oc...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>is also</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156030</th>\n",
       "      <td>156031</td>\n",
       "      <td>8542</td>\n",
       "      <td>a joke in the United States</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156031</th>\n",
       "      <td>156032</td>\n",
       "      <td>8543</td>\n",
       "      <td>The movie 's downfall is to substitute plot fo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156032</th>\n",
       "      <td>156033</td>\n",
       "      <td>8543</td>\n",
       "      <td>The movie 's downfall</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156033</th>\n",
       "      <td>156034</td>\n",
       "      <td>8543</td>\n",
       "      <td>is to substitute plot for personality .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156034</th>\n",
       "      <td>156035</td>\n",
       "      <td>8543</td>\n",
       "      <td>is to substitute plot for personality</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156035</th>\n",
       "      <td>156036</td>\n",
       "      <td>8543</td>\n",
       "      <td>to substitute plot for personality</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156036</th>\n",
       "      <td>156037</td>\n",
       "      <td>8543</td>\n",
       "      <td>substitute plot for personality</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156037</th>\n",
       "      <td>156038</td>\n",
       "      <td>8543</td>\n",
       "      <td>substitute plot</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156038</th>\n",
       "      <td>156039</td>\n",
       "      <td>8543</td>\n",
       "      <td>for personality</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156039</th>\n",
       "      <td>156040</td>\n",
       "      <td>8544</td>\n",
       "      <td>The film is darkly atmospheric , with Herrmann...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156040</th>\n",
       "      <td>156041</td>\n",
       "      <td>8544</td>\n",
       "      <td>is darkly atmospheric , with Herrmann quietly ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156041</th>\n",
       "      <td>156042</td>\n",
       "      <td>8544</td>\n",
       "      <td>is darkly atmospheric , with Herrmann quietly ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156042</th>\n",
       "      <td>156043</td>\n",
       "      <td>8544</td>\n",
       "      <td>is darkly atmospheric ,</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156043</th>\n",
       "      <td>156044</td>\n",
       "      <td>8544</td>\n",
       "      <td>is darkly atmospheric</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156044</th>\n",
       "      <td>156045</td>\n",
       "      <td>8544</td>\n",
       "      <td>with Herrmann quietly suggesting the sadness a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156045</th>\n",
       "      <td>156046</td>\n",
       "      <td>8544</td>\n",
       "      <td>Herrmann quietly suggesting the sadness and ob...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156046</th>\n",
       "      <td>156047</td>\n",
       "      <td>8544</td>\n",
       "      <td>Herrmann</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156047</th>\n",
       "      <td>156048</td>\n",
       "      <td>8544</td>\n",
       "      <td>quietly suggesting the sadness and obsession b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156048</th>\n",
       "      <td>156049</td>\n",
       "      <td>8544</td>\n",
       "      <td>suggesting the sadness and obsession beneath H...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156049</th>\n",
       "      <td>156050</td>\n",
       "      <td>8544</td>\n",
       "      <td>suggesting the sadness and obsession</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156050</th>\n",
       "      <td>156051</td>\n",
       "      <td>8544</td>\n",
       "      <td>the sadness and obsession</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156051</th>\n",
       "      <td>156052</td>\n",
       "      <td>8544</td>\n",
       "      <td>sadness and obsession</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156052</th>\n",
       "      <td>156053</td>\n",
       "      <td>8544</td>\n",
       "      <td>sadness and</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156053</th>\n",
       "      <td>156054</td>\n",
       "      <td>8544</td>\n",
       "      <td>beneath Hearst 's forced avuncular chortles</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156054</th>\n",
       "      <td>156055</td>\n",
       "      <td>8544</td>\n",
       "      <td>Hearst 's forced avuncular chortles</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156055</th>\n",
       "      <td>156056</td>\n",
       "      <td>8544</td>\n",
       "      <td>Hearst 's</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156056</th>\n",
       "      <td>156057</td>\n",
       "      <td>8544</td>\n",
       "      <td>forced avuncular chortles</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156057</th>\n",
       "      <td>156058</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular chortles</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156058</th>\n",
       "      <td>156059</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156059</th>\n",
       "      <td>156060</td>\n",
       "      <td>8544</td>\n",
       "      <td>chortles</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156060 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PhraseId  SentenceId  \\\n",
       "0              1           1   \n",
       "1              2           1   \n",
       "2              3           1   \n",
       "3              4           1   \n",
       "4              5           1   \n",
       "5              6           1   \n",
       "6              7           1   \n",
       "7              8           1   \n",
       "8              9           1   \n",
       "9             10           1   \n",
       "10            11           1   \n",
       "11            12           1   \n",
       "12            13           1   \n",
       "13            14           1   \n",
       "14            15           1   \n",
       "15            16           1   \n",
       "16            17           1   \n",
       "17            18           1   \n",
       "18            19           1   \n",
       "19            20           1   \n",
       "20            21           1   \n",
       "21            22           1   \n",
       "22            23           1   \n",
       "23            24           1   \n",
       "24            25           1   \n",
       "25            26           1   \n",
       "26            27           1   \n",
       "27            28           1   \n",
       "28            29           1   \n",
       "29            30           1   \n",
       "...          ...         ...   \n",
       "156030    156031        8542   \n",
       "156031    156032        8543   \n",
       "156032    156033        8543   \n",
       "156033    156034        8543   \n",
       "156034    156035        8543   \n",
       "156035    156036        8543   \n",
       "156036    156037        8543   \n",
       "156037    156038        8543   \n",
       "156038    156039        8543   \n",
       "156039    156040        8544   \n",
       "156040    156041        8544   \n",
       "156041    156042        8544   \n",
       "156042    156043        8544   \n",
       "156043    156044        8544   \n",
       "156044    156045        8544   \n",
       "156045    156046        8544   \n",
       "156046    156047        8544   \n",
       "156047    156048        8544   \n",
       "156048    156049        8544   \n",
       "156049    156050        8544   \n",
       "156050    156051        8544   \n",
       "156051    156052        8544   \n",
       "156052    156053        8544   \n",
       "156053    156054        8544   \n",
       "156054    156055        8544   \n",
       "156055    156056        8544   \n",
       "156056    156057        8544   \n",
       "156057    156058        8544   \n",
       "156058    156059        8544   \n",
       "156059    156060        8544   \n",
       "\n",
       "                                                   Phrase  Sentiment  \n",
       "0       A series of escapades demonstrating the adage ...          1  \n",
       "1       A series of escapades demonstrating the adage ...          2  \n",
       "2                                                A series          2  \n",
       "3                                                       A          2  \n",
       "4                                                  series          2  \n",
       "5       of escapades demonstrating the adage that what...          2  \n",
       "6                                                      of          2  \n",
       "7       escapades demonstrating the adage that what is...          2  \n",
       "8                                               escapades          2  \n",
       "9       demonstrating the adage that what is good for ...          2  \n",
       "10                                demonstrating the adage          2  \n",
       "11                                          demonstrating          2  \n",
       "12                                              the adage          2  \n",
       "13                                                    the          2  \n",
       "14                                                  adage          2  \n",
       "15                        that what is good for the goose          2  \n",
       "16                                                   that          2  \n",
       "17                             what is good for the goose          2  \n",
       "18                                                   what          2  \n",
       "19                                  is good for the goose          2  \n",
       "20                                                     is          2  \n",
       "21                                     good for the goose          3  \n",
       "22                                                   good          3  \n",
       "23                                          for the goose          2  \n",
       "24                                                    for          2  \n",
       "25                                              the goose          2  \n",
       "26                                                  goose          2  \n",
       "27      is also good for the gander , some of which oc...          2  \n",
       "28      is also good for the gander , some of which oc...          2  \n",
       "29                                                is also          2  \n",
       "...                                                   ...        ...  \n",
       "156030                        a joke in the United States          2  \n",
       "156031  The movie 's downfall is to substitute plot fo...          1  \n",
       "156032                              The movie 's downfall          1  \n",
       "156033            is to substitute plot for personality .          1  \n",
       "156034              is to substitute plot for personality          1  \n",
       "156035                 to substitute plot for personality          2  \n",
       "156036                    substitute plot for personality          1  \n",
       "156037                                    substitute plot          2  \n",
       "156038                                    for personality          2  \n",
       "156039  The film is darkly atmospheric , with Herrmann...          2  \n",
       "156040  is darkly atmospheric , with Herrmann quietly ...          2  \n",
       "156041  is darkly atmospheric , with Herrmann quietly ...          2  \n",
       "156042                            is darkly atmospheric ,          2  \n",
       "156043                              is darkly atmospheric          3  \n",
       "156044  with Herrmann quietly suggesting the sadness a...          2  \n",
       "156045  Herrmann quietly suggesting the sadness and ob...          2  \n",
       "156046                                           Herrmann          2  \n",
       "156047  quietly suggesting the sadness and obsession b...          1  \n",
       "156048  suggesting the sadness and obsession beneath H...          2  \n",
       "156049               suggesting the sadness and obsession          2  \n",
       "156050                          the sadness and obsession          2  \n",
       "156051                              sadness and obsession          1  \n",
       "156052                                        sadness and          1  \n",
       "156053        beneath Hearst 's forced avuncular chortles          2  \n",
       "156054                Hearst 's forced avuncular chortles          2  \n",
       "156055                                          Hearst 's          2  \n",
       "156056                          forced avuncular chortles          1  \n",
       "156057                                 avuncular chortles          3  \n",
       "156058                                          avuncular          2  \n",
       "156059                                           chortles          2  \n",
       "\n",
       "[156060 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(path/'train.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 48\n",
    "data_lm = load_data('/notebooks/course-v3/nbs/dl1/data/imdb', 'data_lm.pkl', bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (TextList.from_csv(path, csv_name='train.tsv', delimiter='\\t', cols='Phrase', vocab=data_lm.vocab)\n",
    "             .split_by_rand_pct(0.2)\n",
    "             .label_from_df(cols=3)\n",
    "             .databunch(bs=bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.save('data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(path, 'data.pkl', bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>xxbos reminds us how realistically nuanced a xxmaj robert xxmaj de xxmaj niro performance can be when he is not more xxunk engaged in the shameless self - caricature of ` xxmaj analyze xxmaj this ' xxup xxunk 1999 xxup xxunk and ` xxmaj analyze xxmaj that , ' promised xxup xxunk or threatened xxup xxunk for later this year .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj while there 's likely very little crossover appeal to those without much interest in the xxmaj xxunk xxup xxunk as well as rank frustration from those in the know about xxmaj xxunk 's dumbed - down tactics xxup xxunk , xxmaj much xxmaj ado xxmaj about xxmaj something is an amicable endeavor .</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj some of the most ravaging , gut - wrenching , frightening war scenes since xxunk xxmaj saving xxmaj private xxmaj ryan '' have been recreated by xxmaj john xxmaj woo in this little - known story of xxmaj native xxmaj americans and their role in the second great war .</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos by the time it 's done with us , xxmaj mira xxmaj nair 's new movie has its audience giddy with the delight of discovery , of having been immersed in a foreign culture only to find that human nature is pretty much the same all over .</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj stephen xxmaj xxunk 's documentary is a decomposition of healthy eccentric inspiration and ambition -- wearing a cloak of unsentimental , straightforward text -- when it 's really an exercise in gross xxunk of the delusional personality type .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = text_classifier_learner(data, AWD_LSTM, drop_mult=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! cp /notebooks/course-v3/nbs/dl1/data/imdb/models/fine_tuned_enc.pth {path}/models/fine_tuned_enc.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load_encoder('fine_tuned_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl8VdW5//HPk3kgCYGEMI8CisggUcQRZxxa9dpax1o70PZqq7W9rW1va3/a29raXq21rVJr6aDYwdk6YL0qzgrIjMokEMIQxoSQ6STP74+zAxGTcCA52TnJ9/16nVfOWXudvZ+d6Tlrr7XXMndHRETkQJLCDkBERBKDEoaIiMRECUNERGKihCEiIjFRwhARkZgoYYiISEyUMEREJCZKGCIiEhMlDBERiUlK2AG0p4KCAh86dGjYYYiIJIx58+ZtdffCWOp2qYQxdOhQ5s6dG3YYIiIJw8zWxlpXl6RERCQmShgiIhITJQwREYmJEoaIiMRECUNERGKihCEiIjFRwhARkZgoYYiIJLDnl23mnpdXdcixlDBERBLYv5dt5o+vremQYylhiIgksOpIPRmpyR1yrLglDDO738y2mNmSFrbnmdmTZrbQzJaa2TVNttWb2YLg8US8YhQRSXRVtfVkJnrCAGYC01rZfi2wzN3HA1OBX5pZWrCtyt0nBI9PxjFGEZGEVh1pID3RE4a7zwG2t1YFyDEzA3oEdSPxikdEpCuqrq0nM7VjehfC7MO4GzgCKAUWA9e7e0OwLcPM5prZm2Z2YWgRioh0cl2iDyMGZwMLgP7ABOBuM8sNtg1292LgcuBOMxvR0k7MbHqQXOaWlZXFPWgRkc6kq/RhHMg1wCMetRJYAxwO4O6lwdfVwEvAxJZ24u4z3L3Y3YsLC2NaA0REpMvoLi2MdcDpAGZWBIwGVptZvpmlB+UFwAnAstCiFBHpxKpqGzosYcRtxT0zm0V09FOBmZUANwOpAO5+D3ArMNPMFgMGfMfdt5rZ8cC9ZtZANKHd5u5KGCIizaipqyejgzq945Yw3P2yA2wvBc5qpvx14Kh4xSUi0pVU1XWPPgwREWmDuvoGIg3eLfowRESkDarr6gHUwhARkdZV10VvXeuoPgwlDBGRBNXYwtAlKRERaZUShoiIxKRKfRgiIhKLfX0YShgiItKKvS2MNHV6i4hIK6pqowkjPUUtDBERaUVNpLGFoYQhIiKtaGxhqA9DRERapTu9RUQkJlXBKCklDBERaVVjCyM9RaOkRESkFdV19aSnJJGUZB1yPCUMEZEEVV3XccuzghKGiEjC6sjFk0AJQ0QkYVXXNXTY1OaghCEikrCqutIlKTO738y2mNmSFrbnmdmTZrbQzJaa2TVNtl1tZiuCx9XxjFNEJBF1tT6MmcC0VrZfCyxz9/HAVOCXZpZmZr2Am4HJwLHAzWaWH+dYRUQSSnVX6sNw9znA9taqADlmZkCPoG4EOBt43t23u/sO4HlaTzwiIt1Od+vDuBs4AigFFgPXu3sDMABY36ReSVD2MWY23czmmtncsrKyeMcrItJpVNXVd9jEgxB+wjgbWAD0ByYAd5tZLtDcXSje3A7cfYa7F7t7cWFhYfwiFRHpZKrr6snooKnNIfyEcQ3wiEetBNYAhxNtUQxqUm8g0VaIiIgEquvqyehGLYx1wOkAZlYEjAZWA88BZ5lZftDZfVZQJiIigeq6hg5tYaTEc+dmNovo6KcCMyshOvIpFcDd7wFuBWaa2WKil6G+4+5bg/feCrwT7OoWd2+t81xEpNuJ9mF03Of+uCYMd7/sANtLibYemtt2P3B/POISEUl0dfUN1Dd4t+rDEBGRQ1BV17HLs4IShohIQtq7FkZXuXFPRETio7q2Y1fbAyUMEZGE1HhJqjvd6S0iIoeg8ZKUWhgiItKqfS0MJQwREWlFtRKGiIjEQpekREQkJtV10VFS6vQWEZFW6cY9ERGJyd4+DE0NIiIirVELQ0REYtLYh5Geoj4MERFpRXVdPRmpSZg1t0BpfChhiIgkoGjC6LjLUaCEISKSkKpq6zv0HgxQwhARSUjVkQa1MERE5MCqajv+klTclmg1s/uB84Et7j62me3/BVzRJI4jgEJ3325mHwIVQD0QcffieMUpIpKIaiL1HXqXN8S3hTETmNbSRne/3d0nuPsE4LvAy+6+vUmVU4PtShYiIvvpUn0Y7j4H2H7AilGXAbPiFYuISFdTHemGo6TMLItoS+ThJsUOzDazeWY2PZzIREQ6rzBaGHHrwzgInwBe2+9y1AnuXmpmfYDnzey9oMXyMUFCmQ4wePDg+EcrItIJVNc1kN6F+jBidSn7XY5y99Lg6xbgUeDYlt7s7jPcvdjdiwsLC+MaqIhIZ1Fd14X6MGJhZnnAKcDjTcqyzSyn8TlwFrAknAhFRDqnqhDu9I7nsNpZwFSgwMxKgJuBVAB3vyeodhEw290rm7y1CHg0mB8lBXjQ3Z+NV5wiIonG3UNpYcQtYbj7ZTHUmUl0+G3TstXA+PhEJSKS+GrrG2jwjl1tDzpHH4aIiByEfcuzdqM+DBEROXh7V9tTwhARkdY0JoxuNUpKREQOXhjLs4IShohIwtnXh6FObxERaUVVrfowREQkBtURJQwREYlBda06vUVEJAZqYYiISEyqaqOd3mphiIhIq/bduKdRUiIi0ooq3ektIiKxqKmrxwzSU9TCEBGRVlTV1ZORkkywDESHUcIQEUkw1XUNHd5/AUoYIiIJpyqExZNACUNEJOFUh7A8KyhhiIgkHCUMERGJSZfrwzCz+81si5ktaWH7f5nZguCxxMzqzaxXsG2amb1vZivN7KZ4xSgikoiq6uo7fC0MiG8LYyYwraWN7n67u09w9wnAd4GX3X27mSUDvwHOAcYAl5nZmDjGKSKSUKpqo8NqO1rcEoa7zwG2x1j9MmBW8PxYYKW7r3b3WuAh4II4hCgikpCqI/VkdLEWRkzMLItoS+ThoGgAsL5JlZKgrKX3TzezuWY2t6ysLH6Bioh0EtUhtTBSOvyIH/cJ4DV3b2yNNHfrorf0ZnefAcwAKC4ubrFeK+9nVdlutu2uZceeWrZV1lJeFeGYoflMGpLf5jsp3Z112/ewqGQXizfsYvnGckYX5XDJMYMYVZTTpn2LSPdUHWkgM63jP+/HlDDMbARQ4u41ZjYVGAf82d13tkMMl7LvchREWxSDmrweCJS2w3FadO5dr1IbafhY+aBemVw0YQAXThzA8MIeMe1rzdZKnl+2iRWbd7Niy25WbtnN7poIAGkpSQwvyObN1du479U1TBjUk0uKB3H6EX0oys1o13MSka4rrD6MWFsYDwPFZnYY8AfgCeBB4Ny2HNzM8oBTgCubFL8DjDSzYcAGognl8rYc5wAxcNelE8lOT6ZXdhq9s9PJSE3iheVbePTdDfz6xZXc9X8r6ZeXQfHQXhwzNJ8pw3szspnWwf+9t5mvPfgulbX1FOakM7JPDy4+egCj++YybmAeo4pySEtJYtvuGh59dwN/n7ue7z26GB6F4QXZTB7em+OG92LSkHwG9Mzs8HliRKTzc3eqI+GMkoo1YTS4e8TMLgLudPdfm9m7rb3BzGYBU4ECMysBbgZSAdz9nqDaRcBsd69sfF9wnOuA54Bk4H53X3owJ3Wwpo3t+7GyiycN5OJJA9m0q5rZyzbx9prtvLNmO08ujDZ2ph3Zl29PG7235THztTXc8tQyxvTP5Z4rJzEwP6vF4/Xukc4XTxrOF04cxrKN5byxahtvrNrGUwtLmfX2OgD65KQzaUg+4wb2ZHCvLAbkZzKgZyYFPdKUSES6sZpIA+4dP7U5gLkf+LK/mb0F3Al8H/iEu68xsyXuPjbeAR6M4uJinzt3btz27+5s2FnFw/M2MGPOKmoiDVw+eTDu8Jc313LmmCJ+dekEstIOrWuovsFZvrGc+et2MG/tDuav28H67VUfqZOXmcrxI3pz4sgCTjqskL55GWwur2ZLRTWby2soys1gwqCeJCcpqYh0Rbv21DH+ltn84PwxfOHEYW3en5nNc/fiWOrG+p/tGuArwP8EyWIY8NdDDTBRmRkD87O4/oyRXD55ML964QMeeGsd9Q3Ol04axk3nHNGmf9TJScbYAXmMHZDHZ6cMBWBXVR0bdlSxYWcVG3bsYWlpOa+u3MozSza1uJ/cjBROHFnAySMLGVaQTV5WKj0z0+iZlXrQn0rcnY27qlmwfifbdtdgZpiBYeypjbC9MjpYYOeeOvIyU+mXl0m/nhkM7JnJkQPyyMtM/dg+6xuckh17+HDbHtZuq+TDrXvYWVVLekoy6SlJpKcmMWlwPmeOKVJrSmQ/jYsnhTH5YEwJw92XAV8HMLN8IMfdb4tnYJ1dYU46P77wKK45YRglO6o4ZVRhXI6Tl5lKXmYqY/rn7i1zd1ZvreTVFVvZsaeWvrkZFOVl0CcnndVllcz5oIw5K8p4evHHk0phTjrDemczrCCbAfmZRBqc6rp6quvqqatv7PiPJoWtFTUsWL+TLRU1LcaXkmTkZ6eRl5nKzj11bN29r64ZjC7KYdKQfEb26cGqskqWlu7ivU0V7Kmt31svMzXaf1QTaaA2Uk91XQP31q/mpJEF3HLBWIYVZLf9Gxmoq2+gwZ30EDoMRdpDWMuzQuyjpF4CPhnUXwCUmdnL7n5jHGNLCCMKezAixhFU7cXMWjzukf3z+MT4/sFw4Uo2l1ezc08du6rq2F5Zw7rte1iztZIX3tvM1t21QHTVrsy0ZFKTo7+A0auUTk5G9PLXhEE9mTg4n/49M3Ec92idrPRkctJTPtIKqInUs2lXNeu272H+2p3MXbudxxeUsrsmQo/0FMb0y+WS4kEc0S+HYQU9GNo7i8Kc9I/sI1LfwJ/fWMv/Pv8BZ98xhy+fMpxzxvYjNdlITjIcWLF5N4tKdrKoZBfvb67APZq8UpKNHukpHDusFyceVsCUEb3JSE3mtZVb+deijTy3dBO19Q2cMqqQaWP7cvoRReRmfLwVJNJZhdnCiLUP4113n2hmXwQGufvNZrbI3cfFP8TYxbsPo6upjTSQkmQkxbm/o77BKauooU9O+kEda0t5NT95ejmPLWh+VHVKkjG6bw5j+uWSmpJEpL6BSIOzbXctb6/ZTlVdPclJRlZqMhU1EXLSUzhjTBE5GSk8t3QTm8trSE02jh6cz9FD8pkYJMbCnPT2OnWRdvfuuh1c9NvX+ePnjuHUw/u0eX/x6MNIMbN+wCVEO76lC0jroPWAk5OMvnkHf59Jn9wM7rx0Il88aTglO6qINDRQ3+DUNzhDC7IZ0y+3xT6Zmkg989fu5NWVZWytqOWMMUWcNLJgb/0ffeJIFpTs5Lklm3hz9TZ+P2c1kYboh6fUZCMrLYXstGSy01M4sn8uU0b05rjhvRncK0v9KhKqqr2XpDppHwZwC9Fhrq+5+ztmNhxYEb+wRPZpHAhwMNJTkpkyojdTRvRudntSUtCyGJwPRK8LLy3dxbvrdrK9spY9tfVU1kTYsaeOV1du3dvKGZifyQ1njOLiowcocUgoauqifY2dtg/D3f8B/KPJ69XAxfEKSqSjZaQmM2lILyYN6fWxbe7Oyi27eXP1Nh6ev4Fv/WMh/5y3nh9feBSH9enY/iuRvX0YnXXyQTMbaGaPButbbDazh81sYLyDE+kMzIyRRTlcNWUoj3z1eH5y0VEsKy3nnF/N4bZn3mNZaTmx9AWKtIe9o6Q68dQgfyQ6Fcing9dXBmVnxiMokc4qKcm4fPJgzhxTxP/8axn3vLyKe15eRWFOOieNLOC44b0ZVZTDYX160CO9M8ztKV1NmC2MWH+jC939j01ezzSzG+IRkEgiKMxJ585LJ3LTOUcwZ0UZr6zYyovvbeGR+Rv21mmcf+xzxw/h6MFtn/lYBKLLs0LnbmFsNbMr2Ter7GXAtviEJJI4+uZlcEnxIC4pHkR9g/PhtkpWBrMUr9yymxeWb+bJhaWMG5jH508YxvDCbNZsrWTttj2s376Hw/r04Nyj+jGoV8tzj4k0tbs6Ovt1dnrnTRifB+4G7iC6NsXrRKcLEZFActK+GyrPPjJaVlkT4ZH5Jfzx9Q+54W8LPlK/oEca/5hXwk+feY+jBuRx9pFF9MnNCG5ATCIt2cjJSN17t39Bj/RQLkNI51JeXUdWWjIpyZ13lNQ6ond67xVckrozHkGJdBXZ6SlcNWUoV0wewhurt7G7JsKwgmwG98oiIzWZ9dv38MySjTy9eBO/mP1Bq/vKSkvmh+eP4TPHDNLlrW6sorqOnIxw+sfactQbUcIQiUlSknHCYQUfKx/UK4vpJ49g+skj2FFZS2VthEi9E2lwaiMNlFdHp3XZVVXHY+9u4KZHFjNnRRk/vWgceVma0qQ7qqiOhDadTVsShj7iiLSj/Ow08rPTWtz+qaMHMuOV1fziufdZsG4Ot108jhMPK4j71C7SuZQnaAtDA89FOlBSkvGVU0YwZXhvrn/oXT57/9v0zc1g2ti+nDO2L8VDe2kdlG6gojpCflbLHyziqdWEYWYVNJ8YDMiMS0Qi0qrxg3ry9PUnMXvpZp5evJFZb69j5usfcvTgnvz1i5MPeQEvSQwV1RGG9G6/Kf8PRqu/We7+8YWrRSR0WWkpXDhxABdOHEBlTYTHFmzgB48t4doH5vP7zxaHMoJGOkZ5VXiXpOL2W2Vm9wdTiSxppc5UM1tgZkvN7OUm5R+a2eJgm+YrF2lFdnoKV0wewq0XjuXF98v43qOLNVVJF1ZRHUnIPowDmUn03o0/N7fRzHoCvwWmufs6M9t/YvdT3X1rHOMT6VKumDyEzbuquev/VtI3L5MbzxwVdkjSzqrr6qmtb0jIUVKtcvc5Zja0lSqXA48E93jg7lviFYtId/GNM0exqbyau15YQVqy8dWph6kjvAspr64DILerXZKKwSgg38xeMrN5ZvbZJtscmB2UTw8pPpGEY2b85KKjOG9cP34x+wMuufcNVpftDjssaScVwbQgOSG1MMJMGCnAJOA84GzgB2bW2IY+wd2PBs4BrjWzk1vaiZlNN7O5Zja3rKws7kGLdHYpyUncfdlE7vjMeFZu2c05v3qF+15ZTX2D+jUSXWPCyM3sfi2MEuBZd68M+irmAOMB3L00+LoFeBQ4tqWduPsMdy929+LCwsIOCFuk8zMzLpo4kOe/cTInjSzgx/9azok/+z9+Oft91m3bE3Z4cojKq6KXpLpjC+Nx4CQzSzGzLGAysNzMss0sB8DMsoGzgBZHWolIy/rkZvD7zxYz46pJjCrK4e4XV3Ly7S9y2Yw3eXvN9rDDk4O075JUFxslZWazgKlAgZmVADcDqQDufo+7LzezZ4FFQANwn7svCdYLfzSYXC0FeNDdn41XnCJdnZlx1pF9OevIvpTurOKR+SU88NY6Lrn3DS6Y0J/vnXsERbkZYYcpMajY2+nd9UZJXRZDnduB2/crW01waUpE2lf/nplcd9pIPn/iMH730irunbOafy/bzNdOH8nnjh9KRqqmT+/MGkdJdbkb90Sk88pKS+GbZ43m+W+czJQRvbntmfc4+ecvMvO1NXvXjJbOp6I6ghlkhzT9ixKGSDc2pHc29119DLO+dBxDC7L50ZPLmHr7Szz41jrdLd4JVVRHyElPCW2GYiUMEWHKiN78bfpxPPjFyQzMz+R7jy7me48uJlLfEHZo0kR0Hqnw1kHRtJYiAkQ7x48/rIApI3rzy9kfcPeLK9lSXsOvL5+oGXA7ifIQ55ECtTBEZD9mxrfOHh1MZriFy3//Ftt214QdlhAdJZWbGV4LQwlDRJp11XFD+N2Vk1i+sZxP3v0azy/bHHZI3V55dSS0eaRACUNEWnH2kX15aPpxZKUl86U/z+ULM9/RneIhqqgOtw9DCUNEWjVxcD5PX38S3z/3CN5cvY0z7niZP73+YdhhdUsVamGISGeXmpzEl04ezgvfnMoJI3pz8xNLeXbJxrDD6lbcXS0MEUkcffMy+N2Vkxg/qCc3/n0hyzeWhx1St1FZW0+Dh3eXNyhhiMhBykhNZsZVk8jJSOGLf5qrEVQdZO88UholJSKJpCg3gxlXFVO2u4avPjCf2ohu8Iu38qpwZ6oFJQwROUTjB/Xk5xeP4+0127n1qWVhh9PlVVSHuxYGKGGISBtcOHEAXzppGH95cy2PL9gQdjhd2t7V9tTCEJFE9e1ph3PM0HxuengxKzZXhB1Ol1WuFoaIJLrU5CTuvvxostOT+cpf57G7JhJ2SF1SuVoYItIVFOVmcNdlE1mztZLvPrJYU6PHgUZJiUiXcfyIAr551mieXFjKfz4wn/c26R6N9lReFSE12UhPCe/ftuYsFpF289VTRlAbaeAPr67hmSWbOPvIIr522kjGDsgLO7SE13iXt1k4iydBHFsYZna/mW0xsyWt1JlqZgvMbKmZvdykfJqZvW9mK83spnjFKCLtKynJ+MaZo3j1O6fy9dNH8vqqbZz/61c1jUg7CHseKYjvJamZwLSWNppZT+C3wCfd/Ujg00F5MvAb4BxgDHCZmY2JY5wi0s56ZqVx45mjePU7p3HUgDy+/+gS3RHeRuUhzyMFcUwY7j4H2N5KlcuBR9x9XVB/S1B+LLDS3Ve7ey3wEHBBvOIUkfjJy0zlF58eT3l1HTc/sTTscBJaRcir7UG4nd6jgHwze8nM5pnZZ4PyAcD6JvVKgrJmmdl0M5trZnPLysriGK6IHIrRfXO4/vSRPLVooy5NtUFFdR25XbWFEYMUYBJwHnA28AMzGwU016PT4hg9d5/h7sXuXlxYWBifSEWkTb58ygjGDsjlvx9bwo7K2rDDSUjlVd27hVECPOvule6+FZgDjA/KBzWpNxAoDSE+EWknqclJ3P6p8eyqquNHT+rS1KEIey0MCDdhPA6cZGYpZpYFTAaWA+8AI81smJmlAZcCT4QYp4i0gyP65XLdqSN5fEEp9768KuxwEkqkvoHK2npyM8NtYcTt6GY2C5gKFJhZCXAzkArg7ve4+3IzexZYBDQA97n7kuC91wHPAcnA/e6ujyQiXcB1px3Gii0V/PSZ98hKS+aqKUPDDikhNE63EnYLI24Jw90vi6HO7cDtzZQ/DTwdj7hEJDzJScYdn5lAdV09P3h8KZlpKXxq0sCww+r0Gmeq7c59GCLSDTVOVnjSyAK+/c+F/O2ddZTurKKuXoswtaRxptqwR0lpahAR6XAZqcnce9Ukrr7/bb7z8GIAzKB3djqnjCrktouPIjVZn2cbNa62F/ad3koYIhKKrLQU/vKFybyxahubyqvZtKuatdsqeXh+CclJ8LOLx4U6b1Jn0hlW2wMlDBEJUUZqMqce3ucjZYN7Z3PXCyvo3zOTG84YFVJkncve1fa66igpEZFD8Y0zRrJhRxV3/juaNC4pHnTgN3VxnWG1PVDCEJFOxsz46X8cxebyar73yGIKc9I5dXSfA7+xC9MoKRGRFqSlJPG7K49mVFEOX/zTXO57ZXW3XsWvorqOzNTk0AcCKGGISKeUk5HK3758HGceUcSP/7Wc62a9S2U3XS+8M8wjBUoYItKJ5WSk8rsrj+amcw7nmcUbufA3r/Hqiq3URrrXPRsVNXWdImGEH4GISCvMjK+cMoKjBuTx9VnvcuUf3iInPYWTRxVy+hF9OG9cP9JTksMOM64qqiPkZobb4Q1KGCKSIE44rIBXvnMqr63cxgvLN/PCe1v41+KNPL6glBmfndSlk0Z5VR15WWlhh6GEISKJIysthTPHFHHmmCIaGpwH317Hfz+2hGsfmM9vr5hEWkrXvMpeUR1hYK+ssMNQH4aIJKakJOPK44Zw6wVH8u/lW7j+oXeJdNH5qMqrI6HPIwVKGCKS4K6aMpQfnD+GZ5Zs4ht/X0h9Q9cbflteXRf6PFKgS1Ii0gV84cRh1EYa+Nmz73F43xyuPfWwsENqNzWRemojDZ1ilJRaGCLSJXzllOGcN64fd/77A5aW7go7nHazbx4pXZISEWkXZsaPLxhLz6w0bvzbQmoi9WGH1C7KqxrnkVILQ0Sk3eRnp/Gzi4/i/c0V3PH8irDDaRd755FK78ItDDO738y2mNmSFrZPNbNdZrYgePywybYPzWxxUD43XjGKSNdz2uFFXHrMIGbMWcW8tdvDDqfNusslqZnAtAPUecXdJwSPW/bbdmpQXhyf8ESkq/rv88fQv2cmN/59YcLPP7Vow04ABuZnhhxJHBOGu88BEj+9i0jC6ZGewi8+PZ512/fw02eWhx1Omzy1cCMTBvWkf88unDBiNMXMFprZM2Z2ZJNyB2ab2Twzmx5WcCKSuI4b3psvnjiMv765jpfe3xJ2OIdkddlulm0s5/xx/cIOBQg3YcwHhrj7eODXwGNNtp3g7kcD5wDXmtnJLe3EzKab2Vwzm1tWVhbfiEUkoXzzrNGMKurBt/+5iB2VtWGHc9CeWrQRgPO6e8Jw93J33x08fxpINbOC4HVp8HUL8ChwbCv7meHuxe5eXFhY2AGRi0iiyEhN5n8vmcCOPbX84PFmx990ak8tKuWYofn0ywv/chSEmDDMrK+ZWfD82CCWbWaWbWY5QXk2cBaQeD9pEekUxg7I44YzRvHUoo08vmBD2OHE7IPNFXyweTfnj+sfdih7xe1OEDObBUwFCsysBLgZSAVw93uATwFfNbMIUAVc6u5uZkXAo0EuSQEedPdn4xWniHR9Xz55OP9evpmbn1jKmWOKyEoL/ya4A3lq0UaSDM45qm/YoewVt++au192gO13A3c3U74aGB+vuESk+0lJTuKmaYfzmRlv8tTCjVxyzKCwQ2qVu/PUolImD+tNn5yMsMPZK+xRUiIiHeLYYb0Y2acHD7y1NuxQDmj5xgpWl1V2ms7uRkoYItItmBlXTB7MwpJdLC7p3JMTPrWolOQk45yxnedyFGh6cxHpRv5j0kB+9uz7PPDWWm4bOC7scACoqq3nrDtfpr7eOXJAHmP75/H4glKOH9Gb3j3Sww7vI9TCEJFuIzcjlQsm9OfxBaWUV9eFHQ4ATy4sZf32Kg7vl8uqst3c+cIHbNhZxQUTBoQd2seohSEi3coVk4fw0DvreXT+Bq4+fmg0cmqyAAAM10lEQVSosbg7f37zQ0YX5fCHq4sxM3bXRFi3bQ+H980JNbbmqIUhIt3KUQPzGD8wjwfeWot7uMu5LizZxZIN5Vw5ZQjBrQT0SE9hTP9ckpIs1Niao4QhIt3OFZOH8MHm3bzz4Y5Q4/jLG2vJTkvmoomd7/JTc5QwRKTb+cT4/uRkpPDL2e+zYnNFKDHsqKzlyUWlXHT0AHqkJ0bvgBKGiHQ7mWnJ3HjmKOav28GZd8zhknve4LF3N3Tosq7/mLee2kgDVx43pMOO2VZKGCLSLV1zwjDe+O7p3HTO4WyuqOaGvy3gs394m7r6hrgfu6HB+eub6zh2aC8O75sb9+O1FyUMEem2Cnqk85VTRvDiN6fyk4uO4q0127ntmffiftw5K8pYt30PV05JnNYFaFitiAhJScblkwfzweYK/vDqGsYP6sknx7f/LLE7Kmt5ZeVW7n15FQU90ph2ZOe6k/tAlDBERALfO/cIlmzYxXf+uYjD++Ywqqh97oX497LN3P3iShaW7MQdemal8t/njSEtJbEu8ljY45DbU3Fxsc+dOzfsMEQkgW0pr+a8X79Kj/QUHrv2BPIyU9u0v517ajnp5y9S0COdCyb055RRhYwb2JPkTnKfhZnNc/fiWOomVnoTEYmzPrkZ/Obyo1m3fQ+n3P4iP316Oeu37znk/f3u5VXsrolwz5WTuOGMUUwcnN9pksXBUsIQEdnPscN68fcvT+H4Eb2579U1nHz7i3xh5jus23ZwiWNzeTUzX/uQCycMYHQnnOrjYKkPQ0SkGZOG5DNpyCQ27qpi1lvrmPn6h3xmxhvM+tJxDC3Ijmkfd72wgvoG5xtnjIpztB1DLQwRkVb0y8vkxrNG87cvT6Em0sBnZrzB6rLdB3zf2m2V/O2d9Vx27GAG987qgEjjL24Jw8zuN7MtZrakhe1TzWyXmS0IHj9ssm2amb1vZivN7KZ4xSgiEqsj+uUy60vHEal3Lp3xJiu3tJ40/vf5D0hJNr522mEdFGH8xbOFMROYdoA6r7j7hOBxC4CZJQO/Ac4BxgCXmdmYOMYpIhKT0X1zmDX9OBo8mjQeX7CB+oaPjzRdsH4nTyws5ZoThtEnt/Osyd1WcUsY7j4H2H4Ibz0WWOnuq929FngIuKBdgxMROUSjinJ4aPpx9M5O4/qHFnD2nXN4YmEpVbX1PLmwlKv+8BYX/fY1emam8pWTR4QdbrsKu9N7ipktBEqBb7n7UmAAsL5JnRJgchjBiYg057A+OTxz/Uk8s2QTv3rhA74+611SkoxIgzOgZyZfP20knzlmEHlZbbuHo7MJM2HMB4a4+24zOxd4DBgJNDdAucW7C81sOjAdYPDgwfGIU0TkY5KSjPPG9eOcsX15eslG3l6znTPHFHH8iIKEvc/iQEJLGO5e3uT502b2WzMrINqiGNSk6kCiLZCW9jMDmAHRO73jFK6ISLOSkozzx/Xn/HHtP/dUZxPasFoz62vBmoRmdmwQyzbgHWCkmQ0zszTgUuCJsOIUEZGouLUwzGwWMBUoMLMS4GYgFcDd7wE+BXzVzCJAFXCpRye2ipjZdcBzQDJwf9C3ISIiIdLkgyIi3ZgmHxQRkXanhCEiIjFRwhARkZgoYYiISEyUMEREJCZhTw3SbszsE8BWM1u736Y8YNcBypq+bu5549cCYOshhthcHLFsb8/44dDP4UDxt1antXj3f32g54r/4Osc6HeopfNpz/hbi+9A2/U3HN/4h8S8B3fvEg9gRqzl+5c1fd3c8yZf57Z3fB0Zf1vO4UDxH8w5HGz87fEzUPwtl7V0Pu0ZfyznoL/hcOOP5dGVLkk9eRDl+5c9eYDnLe37YBxoH4kef2t1Wot3/9exPD8Uir/lspbOpz3jj2Ufif43kOjxH1CXunEv3sxsrsd4g0tnlejnoPjDpfjDFXb8XamF0RFmhB1AO0j0c1D84VL84Qo1frUwREQkJmphiIhITLptwjCz+81si5ktOYT3TjKzxWa20szuapymPdj2NTN738yWmtnP2zfqj8TQ7vGb2Y/MbIOZLQge57Z/5B+JIy4/g2D7t8zMgzVW4iJOP4NbzWxR8P2fbWZxW2QhTvHfbmbvBefwqJn1bP/I98YQj/g/HfztNphZXPoK2hJ3C/u72sxWBI+rm5S3+jdySNo6zCpRH8DJwNHAkkN479vAFKKrAz4DnBOUnwr8G0gPXvdJsPh/RHSp3IT9GQTbBhGdHn8tUJBI8QO5Tep8HbgnweI/C0gJnv8M+FmCxX8EMBp4CSjuTHEHMQ3dr6wXsDr4mh88z2/tHNvy6LYtDHefA2xvWmZmI8zsWTObZ2avmNnh+7/PzPoR/aN+w6M/lT8DFwabvwrc5u41wTG2JFj8HSqO53AH8G1aWdq3PcQjfm+yEiWQTRzPIU7xz3b3SFD1TaIrZiZS/Mvd/f14xdyWuFtwNvC8u2939x3A88C0eP2dd9uE0YIZwNfcfRLwLeC3zdQZQHQZ2UYlQRnAKOAkM3vLzF42s2PiGu3HtTV+gOuCywn3m1l+/EJtUZvOwcw+CWxw94XxDrQFbf4ZmNn/mNl64Argh3GMtTnt8TvU6PNEP9l2pPaMvyPFEndzBgDrm7xuPJe4nGOXmRqkrcysB3A88I8ml/rSm6vaTFnjp8AUos3C44BjgL+b2fAgw8dVO8X/O+DW4PWtwC+J/tF3iLaeg5llAd8nelmkw7XTzwB3/z7wfTP7LnAd0dUq46694g/29X0gAjzQnjG2pj3j70itxW1m1wDXB2WHAU+bWS2wxt0vouVzics5KmHskwTsdPcJTQvNLBmYF7x8gug/1abN7IFAafC8BHgkSBBvm1kD0blfyuIZeKDN8bv75ibv+z3wVDwDbkZbz2EEMAxYGPzhDQTmm9mx7r4pzrFD+/wONfUg8C86KGHQTvEHHa/nA6d3xIelJtr7+99Rmo0bwN3/CPwRwMxeAj7n7h82qVJCdCnsRgOJ9nWUEI9zjEenTqI8gKE06XgCXgc+HTw3YHwL73uHaCuisTPp3KD8K8AtwfNRRJuKlkDx92tS5xvAQ4n2M9ivzofEsdM7Tj+DkU3qfA34Z4LFPw1YBhTG+3cnnr8/xLHT+1DjpuVO7zVEr2zkB897xXKOhxR3R/xQO+MDmAVsBOqIZuMvEP10+iywMPil/2EL7y0GlgCrgLvZdwNkGvDXYNt84LQEi/8vwGJgEdFPYv3iFX+8zmG/Oh8S31FS8fgZPByULyI698+ABIt/JdEPSguCRzxHecUj/ouCfdUAm4HnOkvcNJMwgvLPB9/3lcA1B/M3crAP3ektIiIx0SgpERGJiRKGiIjERAlDRERiooQhIiIxUcIQEZGYKGFIl2Zmuzv4ePeZ2Zh22le9RWetXWJmTx5o5lcz62lm/9kexxZpjobVSpdmZrvdvUc77i/F902uF1dNYzezPwEfuPv/tFJ/KPCUu4/tiPik+1ELQ7odMys0s4fN7J3gcUJQfqyZvW5m7wZfRwflnzOzf5jZk8BsM5tqZi+Z2T8tuvbDA41rDQTlxcHz3cFEggvN7E0zKwrKRwSv3zGzW2JsBb3BvgkWe5jZC2Y236LrHVwQ1LkNGBG0Sm4P6v5XcJxFZvb/2vHbKN2QEoZ0R78C7nD3Y4CLgfuC8veAk919ItFZYn/S5D1TgKvd/bTg9UTgBmAMMBw4oZnjZANvuvt4YA7wpSbH/1Vw/APO7xPMhXQ60bvvAaqBi9z9aKJrsPwySFg3AavcfYK7/5eZnQWMBI4FJgCTzOzkAx1PpCWafFC6ozOAMU1mBs01sxwgD/iTmY0kOrNnapP3PO/uTdcweNvdSwDMbAHRuYFe3e84teybwHEecGbwfAr71iZ4EPhFC3FmNtn3PKJrHUB0bqCfBP/8G4i2PIqaef9ZwePd4HUPoglkTgvHE2mVEoZ0R0nAFHevalpoZr8GXnT3i4L+gJeabK7cbx81TZ7X0/zfUp3v6yRsqU5rqtx9gpnlEU081wJ3EV0noxCY5O51ZvYhkNHM+w34qbvfe5DHFWmWLklJdzSb6DoTAJhZ47TSecCG4Pnn4nj8N4leCgO49ECV3X0X0eVav2VmqUTj3BIki1OBIUHVCiCnyVufAz4frLeAmQ0wsz7tdA7SDSlhSFeXZWYlTR43Ev3nWxx0BC8jOi09wM+Bn5rZa0ByHGO6AbjRzN4G+gG7DvQGd3+X6EymlxJdlKjYzOYSbW28F9TZBrwWDMO93d1nE73k9YaZLQb+yUcTishB0bBakQ4WrAxY5e5uZpcCl7n7BQd6n0jY1Ich0vEmAXcHI5t20oHL4Iq0hVoYIiISE/VhiIhITJQwREQkJkoYIiISEyUMERGJiRKGiIjERAlDRERi8v8BQxZF+E7QgmgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:55 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.074871</td>\n",
       "      <td>0.944552</td>\n",
       "      <td>0.612553</td>\n",
       "      <td>00:55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-2, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (124848 items)\n",
       "x: TextList\n",
       "xxbos a series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .,xxbos a series of escapades demonstrating the adage that what is good for the goose,xxbos a series,xxbos a,xxbos series\n",
       "y: CategoryList\n",
       "1,2,2,2,2\n",
       "Path: /storage/rotten-tomatos-sentiment-analysis;\n",
       "\n",
       "Valid: LabelList (31212 items)\n",
       "x: TextList\n",
       "xxbos how xxmaj john xxmaj malkovich 's reedy xxunk will pronounce his next line,xxbos very strong,xxbos that 's been acted out,xxbos a subzero version of xxmaj monsters , xxmaj inc. ,,xxbos unimaginable\n",
       "y: CategoryList\n",
       "2,3,2,2,1\n",
       "Path: /storage/rotten-tomatos-sentiment-analysis;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(60003, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(60003, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1150, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1150, 1150, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1150, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f30a4d452f0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/storage/rotten-tomatos-sentiment-analysis'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True)], callbacks=[RNNTrainer\n",
       "learn: RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (124848 items)\n",
       "x: TextList\n",
       "xxbos a series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .,xxbos a series of escapades demonstrating the adage that what is good for the goose,xxbos a series,xxbos a,xxbos series\n",
       "y: CategoryList\n",
       "1,2,2,2,2\n",
       "Path: /storage/rotten-tomatos-sentiment-analysis;\n",
       "\n",
       "Valid: LabelList (31212 items)\n",
       "x: TextList\n",
       "xxbos how xxmaj john xxmaj malkovich 's reedy xxunk will pronounce his next line,xxbos very strong,xxbos that 's been acted out,xxbos a subzero version of xxmaj monsters , xxmaj inc. ,,xxbos unimaginable\n",
       "y: CategoryList\n",
       "2,3,2,2,1\n",
       "Path: /storage/rotten-tomatos-sentiment-analysis;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(60003, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(60003, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1150, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1150, 1150, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1150, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f30a4d452f0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/storage/rotten-tomatos-sentiment-analysis'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True)], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): Embedding(60003, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(60003, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True)\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): Embedding(60003, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(60003, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 01:03 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.952728</td>\n",
       "      <td>0.940649</td>\n",
       "      <td>0.645617</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-2)\n",
    "learn.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (124848 items)\n",
       "x: TextList\n",
       "xxbos a series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .,xxbos a series of escapades demonstrating the adage that what is good for the goose,xxbos a series,xxbos a,xxbos series\n",
       "y: CategoryList\n",
       "1,2,2,2,2\n",
       "Path: /storage/rotten-tomatos-sentiment-analysis;\n",
       "\n",
       "Valid: LabelList (31212 items)\n",
       "x: TextList\n",
       "xxbos how xxmaj john xxmaj malkovich 's reedy xxunk will pronounce his next line,xxbos very strong,xxbos that 's been acted out,xxbos a subzero version of xxmaj monsters , xxmaj inc. ,,xxbos unimaginable\n",
       "y: CategoryList\n",
       "2,3,2,2,1\n",
       "Path: /storage/rotten-tomatos-sentiment-analysis;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(60003, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(60003, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1150, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1150, 1150, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1150, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f30a4d452f0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/storage/rotten-tomatos-sentiment-analysis'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True)], callbacks=[RNNTrainer\n",
       "learn: RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (124848 items)\n",
       "x: TextList\n",
       "xxbos a series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .,xxbos a series of escapades demonstrating the adage that what is good for the goose,xxbos a series,xxbos a,xxbos series\n",
       "y: CategoryList\n",
       "1,2,2,2,2\n",
       "Path: /storage/rotten-tomatos-sentiment-analysis;\n",
       "\n",
       "Valid: LabelList (31212 items)\n",
       "x: TextList\n",
       "xxbos how xxmaj john xxmaj malkovich 's reedy xxunk will pronounce his next line,xxbos very strong,xxbos that 's been acted out,xxbos a subzero version of xxmaj monsters , xxmaj inc. ,,xxbos unimaginable\n",
       "y: CategoryList\n",
       "2,3,2,2,1\n",
       "Path: /storage/rotten-tomatos-sentiment-analysis;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(60003, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(60003, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1150, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1150, 1150, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1150, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f30a4d452f0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/storage/rotten-tomatos-sentiment-analysis'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True)], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): Embedding(60003, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(60003, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True)\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): Embedding(60003, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(60003, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 01:29 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.908944</td>\n",
       "      <td>0.882339</td>\n",
       "      <td>0.661765</td>\n",
       "      <td>01:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-3)\n",
    "learn.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('third')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (124848 items)\n",
       "x: TextList\n",
       "xxbos a series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .,xxbos a series of escapades demonstrating the adage that what is good for the goose,xxbos a series,xxbos a,xxbos series\n",
       "y: CategoryList\n",
       "1,2,2,2,2\n",
       "Path: /storage/rotten-tomatos-sentiment-analysis;\n",
       "\n",
       "Valid: LabelList (31212 items)\n",
       "x: TextList\n",
       "xxbos how xxmaj john xxmaj malkovich 's reedy xxunk will pronounce his next line,xxbos very strong,xxbos that 's been acted out,xxbos a subzero version of xxmaj monsters , xxmaj inc. ,,xxbos unimaginable\n",
       "y: CategoryList\n",
       "2,3,2,2,1\n",
       "Path: /storage/rotten-tomatos-sentiment-analysis;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(60003, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(60003, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1150, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1150, 1150, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1150, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f98d1d592f0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/storage/rotten-tomatos-sentiment-analysis'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True)], callbacks=[RNNTrainer\n",
       "learn: RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (124848 items)\n",
       "x: TextList\n",
       "xxbos a series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .,xxbos a series of escapades demonstrating the adage that what is good for the goose,xxbos a series,xxbos a,xxbos series\n",
       "y: CategoryList\n",
       "1,2,2,2,2\n",
       "Path: /storage/rotten-tomatos-sentiment-analysis;\n",
       "\n",
       "Valid: LabelList (31212 items)\n",
       "x: TextList\n",
       "xxbos how xxmaj john xxmaj malkovich 's reedy xxunk will pronounce his next line,xxbos very strong,xxbos that 's been acted out,xxbos a subzero version of xxmaj monsters , xxmaj inc. ,,xxbos unimaginable\n",
       "y: CategoryList\n",
       "2,3,2,2,1\n",
       "Path: /storage/rotten-tomatos-sentiment-analysis;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(60003, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(60003, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1150, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1150, 1150, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1150, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f98d1d592f0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/storage/rotten-tomatos-sentiment-analysis'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True)], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): Embedding(60003, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(60003, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True)\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): Embedding(60003, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(60003, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('third')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 04:21 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.865810</td>\n",
       "      <td>0.818252</td>\n",
       "      <td>0.669742</td>\n",
       "      <td>02:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.842884</td>\n",
       "      <td>0.825188</td>\n",
       "      <td>0.672049</td>\n",
       "      <td>02:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('forth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = TextList.from_csv(path, csv_name='test.tsv', delimiter='\\t', cols='Phrase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Your data is neither split nor labeled, can't turn it in a `DataBunch` yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-ac911e773cb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatabunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/data_block.py\u001b[0m in \u001b[0;36mdatabunch\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdatabunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;34m\"To throw a clear error message when the data wasn't split and labeled.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Your data is neither split nor labeled, can't turn it in a `DataBunch` yet.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mEmptyLabelList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mItemList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Your data is neither split nor labeled, can't turn it in a `DataBunch` yet."
     ]
    }
   ],
   "source": [
    "db=test.databunch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = load_learner(path, test=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, y = learn.get_preds(ds_type=DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66292"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0477, 0.6304, 0.2829, 0.0269, 0.0121])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-ddaff89e4629>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_item\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "learn.data.test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = [pred.argmax().item() for pred in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  Sentiment\n",
       "0    156061          2\n",
       "1    156062          2\n",
       "2    156063          2\n",
       "3    156064          2\n",
       "4    156065          2"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('sampleSubmission.csv');submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Sentiment'] = sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  Sentiment\n",
       "0    156061          1\n",
       "1    156062          1\n",
       "2    156063          3\n",
       "3    156064          3\n",
       "4    156065          3"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(path/'submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
      "100%|█████████████████████████████████████████| 583k/583k [00:00<00:00, 771kB/s]\n",
      "Successfully submitted to Sentiment Analysis on Movie Reviews"
     ]
    }
   ],
   "source": [
    "! kaggle competitions submit sentiment-analysis-on-movie-reviews -f {path/'submission.csv'} -m \"My submission\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some sanity tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['negative', 'somewhat negative', 'neutral', 'somewhat positive', 'positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes[learn.predict('I really love it')[1].item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'somewhat negative'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes[learn.predict('I really dont like it')[1].item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'somewhat negative'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes[learn.predict('I very dissapointed with that')[1].item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes[learn.predict('Simply the best')[1].item()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
